\section{Data Analysis}
Wrapping around the plug-in model of our system there are some auxiliary
software (scripts)
which follow and automate all the simulations, from the beginning (building up
the simulation scenario) to the post-processing data analysis.

Thus, after a bunch of simulation runs handled as previously explained,
 we performed a data analysis in order to
figure out the effectiveness of a time analysis attack.  

In this section we will illustrate the software tools we used for
handling the
simulation runs and the software tools we used in the analysis phase. 
Eventually we will 
present the empirical results
obtained.
\subsection{Netbuilder and Launcher Scripts}
As described in \ref{sec:Shadow}
The Shadow simulator use a XML file to describe the network,
we automatize this process with a python script called the net-builder script.\\
This script will so build a scenario based on some input parameters as:
\begin{itemize}
\item The number of TOR relays in the simulation.
\item The number of TOR exit nodes in the simulation.
\item The number of TOR 4authorities\footnote{A 4 Authority node is simply the
database that keep track of the state of the TOR network and the list
of the TOR relays/exit-nodes} nodes in the simulation.
\item The number of clients (simpletcp) of the simulation.
\item The number of servers (simpletcp) of the simulation.
\item The percentage of clients tracked by an autosys plug-in.
\item The percentage of servers tracked by an autosys plug-in.
\item The density of the network-requests.
\end{itemize}

When the others parameters are self-esplicative, the density parameter is somewhat
that deserves more that two words on.
This parameter specify the time interval between every connection made from the
simpletcp plug-in to emulate the behaviour of different type of networks.
We defined three behaviours to our network study:

\begin{itemize}
\item Slow:\\minimum: a mean of 800 milliseconds of sleep time between every connection,\\
            maximum: a mean of 2 seconds of sleep time between every connection.
\item Average:\\minimum: a mean of 80 milliseconds of sleep time between every connection,\\
               maximum: a mean of 1 second of sleep time between every connection.
\item Fast:\\minimum: a mean of 20 milliseconds of sleep time between every connection\\
            maximum: a mean of 100 milliseconds of sleep time between every connection.
\end{itemize}

This normal distributed values are computed for every simpletcp client
(which will compute a random uniform distributed value as described in \ref{sec:simpletcpclient}).\\

The second auxiliary script we used is a bash script that helped us in the
automatic run of the simulations.
This script will run a bunch of simulation using the algorithm \ref{alg:launcher}.

\begin{algorithm}[H]
\caption{Launcher script}
\begin{algorithmic}[2]
\For{($simulation\_run \gets 1$; $simulation\_run <= steps$; $simulation\_run++$)}
	\For{($sim\_id \gets 1$; $sim\_id <= simulations\_per\_step$; $sim\_id++$)}
		\ForAll {$density$ $in$ $(slow, fast, average)$}
		\If {The client trace percentage is not fixed}
			\State $client\_trace\_value \gets sim\_id/simulations\_per\_step$
		\EndIf
		\If {The server trace percentage is not fixed}
			\State $server\_trace\_value \gets sim\_id/simulations\_per\_step$
		\EndIf
		\If{A configuration is present for $<sim\_id, density>$ And the percentages are fixed}
			\State Use the previous configuration
		\Else
			\State Generate a new configuration with net-builder
		\EndIf
		\State Launch the Shadow Simulator with the appropriate configuration.
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\label{alg:launcher}
\end{algorithm}

From this algorithm we can see that we can use this script to create a set of
simulations with some linear modifications to the numbers of the traced clients
or the number of the traced servers (or a combination of the two).
We can also declare more than one run on this bunch of simulations, this can
be useful to compute the mean values from the same configuration file, else we
can generate a new configuration file starting from some input parameters.

After the launch we can pass the simulation raw data to the analyzer script.

\subsection{Analyzer Script}
The analyzer script takes a log file, generated previously by the logger
server, as input and tries to
ascertain which clients were communicating with which server during the
simulation. The log file is a list of entries that are formatted as described in
 figure \ref{fig:analyzer_pack_struct} and the figure
\ref{fig:example_log_file} shows an example of it.
\begin{figure}[H]
\centering
\begin{lstlisting}[language=bash,frame=single, numbers=left]
...
c;client10;1420000000
s;server7;1420008031
c;client6;1420005867
s;server9;1420146660
s;server6;1420205384
s;server8;1420252482
c;client0;1420680882
c;client1;1421017740
s;server7;1421023888
s;server2;1421156205
c;client8;1421160529
s;server3;1421318345
s;server0;1421332488
c;client7;1421487295
c;client4;1421634744
s;server9;1421726485
c;client2;1421827747
...
\end{lstlisting}
\caption{Analyzer log file fragment example.}
\label{fig:example_log_file}
\end{figure}
The script scans the log file and for each line checks whatever the entry is
related to a client or a server. If the entry refers to a client
connection request it scans in a nestled loop the server connection entries
that may be related to that client. The nested loop does not scan the whole
file until its end, but it stops after a sufficient amount of
read entries. In particular, the amount of entries to be read is
measured in time: from a client entry, the scan goes
ahead until the difference between the time-stamp of the current scanned 
entry and the time-stamp of the starting client entry is not greater
than a fixed threshold $thr_{max}$. For our experiment we chose a limit of 6
seconds as it is an enough high latency
value for a connection acceptance. Likely, the average latency for a
connection response, even passing through the Tor network, is
considerably smaller than 6 seconds but anyway we can over-esteem a bit this
value without unexpected bad consequences. On the other hand, an under-esteem of
this value would threaten the analysis results. 

Furthermore, from a client
entry the nestled scan starts reading from the entry that is 100 ms far
from the client start point. This lower threshold, $thr_{min}$, is needed in order to
 filter those server entries that registered a connection time-stamp
that results too young for being related to the client start point. This
lower limit is more critical: a too low limit would guarantee false
positive results and a too high limit would drop the right results.
We will see later that after some tests, a value around 100ms seemed to maximize 
the clients servers relation matching. %TODO in empirical results

The analysis proceeds by recording a set of possible server candidates 
 per each client. Each server candidate assumes a $pmatch$ value that
indicates how much a server candidate can be the real
\footnote{The term ''real`` should not be misunderstood with
non-simulated but should be intended as non-estimated.}
 server that
established a connection with the client. The $pmatch$ value is defined
as following:
\begin{equation}
pmatch = 1 - \frac{\Delta_t - thr_{min}}{thr_{max}}
\end{equation}
where $\Delta_t$ is the time distance between the server entry time-stamp and
the client entry time-stamp.

As instance let us consider the server candidates related to the first
client entry, $client10$, of the example log
fragment shown in figure \ref{fig:example_log_file}: 
$server7$ is not considered at all in the pmatch calculation  as $\Delta_t$ 
is lesser than $thr_{min}$; then the $pmatch$ values for the first server
candidates related to the $client10$ are shown in figure \ref{fig:pmatch}:
\begin{figure}[h]
\begin{lstlisting}[language=bash,frame=single, numbers=left]
candidate 	pmatch
server9 	0.992
server6 	0.982
server8 	0.975
server7  	0.846
server2  	0.823 
server3  	0.769
server0  	0.794
...
\end{lstlisting}
\caption{$pmatch$ values for server candidates related to $client10$}
\label{fig:pmatch}
\end{figure}

Clearly the $pmatch$ probability is higher when the server connection is
closer to $thr_{min}$ meaning that the likelihood of a server
candidate to be the real server for the related client decreases when
the server connection acceptance attempted far from 100ms. At the
first look this simple
assumption does not seem to provide a robust evaluation but, as the
experiments results will confirm, it seems fair considering the average
calculated with thousands of records. Focusing on the context we can realize that 
even if sometimes some server candidate could assume a $pmatch$ value
that is higher than the $pmatch$ value of the real server, or even if sometimes the
real server could skip at all the $pmatch$ evaluation (e.g.
for a too small $\Delta_t$), the real server mostly accepts
the connections around the $thr_{min}$ threshold if well
estimated.

The analyzer script also collects information about the
real connections logged by the simple-tcp applications. With this
information the analyzer can tell us how much the estimated results are
close to the real ones. Obviously, in a real time analysis attack the real connections
information cannot be obtain by the client and server applications themselves 
but in a simulation environment, we can better figure out how a real
time analysis attack may be effective.
%TODO tell that the final pmatch value is the pmatch average for each
%candidate and show its formula

 Moreover by a set of simulations
that provide the use of the real connections logged data, some
parameters like $thr_{min}$ and $thr_{max}$ may be evaluated for 
experimenting the attack in a real scenario. Also, the use of this technique
by an attacker himself cannot be ruled out. 
\newpage
\subsection{Empirical Results}
\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graphs/s_server_mport_average_only.pdf}
\includegraphics[scale=0.35]{graphs/s_server_mport.pdf}
\includegraphics[scale=0.35]{graphs/c_tclient_mport_average_only.pdf}
\includegraphics[scale=0.35]{graphs/c_tclient_mport.pdf}
\caption{Matched portion graphs}
\label{fig:g_mport}
\end{figure}
TODO BLABLABLABLABLA SU MPORT


\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graphs/s_server_pmatch_average_only.pdf}
\includegraphics[scale=0.35]{graphs/s_server_pmatch.pdf}
\includegraphics[scale=0.35]{graphs/c_tclient_pmatch_average_only.pdf}
\includegraphics[scale=0.35]{graphs/c_tclient_pmatch.pdf}
\caption{Matching probability graphs}
\label{fig:g_pmatch}
\end{figure}

TODO BLABLABLA SU PMATCH

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graphs/cs_tport_mport.pdf}
\includegraphics[scale=0.35]{graphs/cs_tport_pmatch.pdf}
\caption{Traced portion graphs}
\label{fig:g_tport}
\end{figure}

TODO BALBALBALBA SU TRACED PORTION


\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graphs/density_clients_ration.pdf}
\caption{Communication density related to the logging capacity}
\label{fig:g_density}
\end{figure}

TODO BLABLABLA SU DENSITY
